{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702 8532\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Recurrent Neural Network\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Parameters Preset\n",
    "alpha = 0.05\n",
    "lamda = 0.001\n",
    "mask = 10\n",
    "\n",
    "# Data load in\n",
    "data = []\n",
    "training_set = []\n",
    "raw_data = open(\"user_cart.json\",'r')\n",
    "unum = raw_data.read().count('\\n')\n",
    "raw_data.seek(0)\n",
    "unum = 0\n",
    "inum = 0\n",
    "lines = raw_data.readlines()\n",
    "for li in lines:\n",
    "    record = json.loads(li)\n",
    "    if(len(record)>10):\n",
    "        thisline = []\n",
    "        for i in range(len(record)):\n",
    "            thisline.append(int(record[i]))\n",
    "            if(int(record[i])>inum):\n",
    "                inum = int(record[i])\n",
    "        data.append(thisline)\n",
    "        training_set.append(thisline[0:int(len(record)*0.8)])\n",
    "        unum = unum + 1\n",
    "print unum, inum\n",
    "# Data understanding\n",
    "# user_size 703(737) item_size 8533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Represent -- 10D features\n",
    "np.random.seed(0)\n",
    "I = np.random.randn(inum+1, mask) * 0.5\n",
    "H = np.zeros((unum+1, mask))\n",
    "U = np.random.randn(mask, mask) * 0.5\n",
    "R = np.random.randn(mask, mask) * 0.5\n",
    "\n",
    "# The random J choose\n",
    "opt_set = []\n",
    "\n",
    "def ResetOpt():\n",
    "    global opt_set\n",
    "    opt_set = []\n",
    "    count = 0\n",
    "    for user in xrange(unum):\n",
    "        new_rand = []\n",
    "        for item in xrange(len(training_set[user])):\n",
    "            j = random.randint(0,8532)\n",
    "            while(j == training_set[user][item]):\n",
    "                j = random.randint(0, 8532)\n",
    "            new_rand.append(j)\n",
    "        opt_set.append(new_rand)\n",
    "    #print len(opt_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmond(x):\n",
    "    return .5 *(1 + np.tanh(.5 * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    global I, U, R, H\n",
    "    #ResetOpt()\n",
    "    for user in xrange(unum):\n",
    "        isum = len(training_set[user])\n",
    "        \n",
    "        H3 = np.zeros((1, 10))\n",
    "        H3 = H3[0]\n",
    "        # The first item\n",
    "        item = 0\n",
    "        #feed-forward\n",
    "        i = training_set[user][item] -1 \n",
    "        I2 = I[i]\n",
    "        A2 = np.dot(H3, R) + np.dot(I2, U)\n",
    "        H2 = np.zeros((1, mask))\n",
    "        H2 = H2[0]\n",
    "        for k in xrange(mask):\n",
    "            H2[k] = sigmond(A2[k])\n",
    "        \n",
    "        # The second item\n",
    "        item = 1\n",
    "        #feed-forward\n",
    "        i = training_set[user][item] -1\n",
    "        j = opt_set[user][item] -1\n",
    "        I1 = I[i]\n",
    "        J1 = I[j]\n",
    "        A1 = np.dot(H2, R) + np.dot(I1, U)\n",
    "        H1 = np.zeros((1, 10))\n",
    "        H1 = H1[0]\n",
    "        for k in xrange(mask):\n",
    "            H1[k] = sigmond(A1[k])\n",
    "        X = np.dot(H2, I1.T) - np.dot(H2, J1.T)\n",
    "        dI1 = H2\n",
    "        dJ1 = -H2\n",
    "        I[i] += alpha *((1 - sigmond(X))* dI1 - lamda * I1)\n",
    "        I[j] += alpha *((1 - sigmond(X))* dJ1 - lamda * J1)\n",
    "        I1 = I[i]\n",
    "        J1 = I[j]\n",
    "        # back-propagation for once\n",
    "        dXH2 = I1 - J1\n",
    "        dHA2 = np.zeros((1, 10))\n",
    "        dHA2 = dHA2[0]\n",
    "        for k in xrange(mask):\n",
    "            dHA2[k] = H2[k] *(1 - H2[k])\n",
    "        dU = np.zeros((10, 10))\n",
    "        dR = np.zeros((10, 10))\n",
    "        Ut = U\n",
    "        Rt = R\n",
    "        U += alpha *((1 - sigmond(X))* dU - lamda * Ut)\n",
    "        R += alpha *((1 - sigmond(X))* dR - lamda * Rt)\n",
    "        \n",
    "        #the third item\n",
    "        item = 2\n",
    "        #feed-forward\n",
    "        i = training_set[user][item]-1\n",
    "        j = opt_set[user][item]-1\n",
    "        Inow = I[i]\n",
    "        Jnow = I[j]\n",
    "        X = np.dot(H1, Inow.T) - np.dot(H1, Jnow.T)\n",
    "        dXInow = H1\n",
    "        dXJnow = -H1\n",
    "        I[i] += alpha *((1 - sigmond(X))* dXInow - lamda * Inow)\n",
    "        I[j] += alpha *((1 - sigmond(X))* dXJnow - lamda * Jnow)\n",
    "        Inow = I[i]\n",
    "        Jnow = I[j]\n",
    "        #back-propagation --first\n",
    "        dXH1 = Inow - Jnow\n",
    "        dHA1 = np.zeros((1, 10))\n",
    "        for k in xrange(mask):\n",
    "            dHA1[0][k] = H1[k] *(1 - H1[k])\n",
    "        dU = np.zeros((10, 10))\n",
    "        dR = np.zeros((10, 10))\n",
    "        dU1 = np.zeros((10, 10))\n",
    "        for k in xrange(mask):\n",
    "            dU[k] = I1[k] * dHA1 * dXH1\n",
    "            dR[k] = H2[k] * dHA1 * dXH1 \n",
    "        Ut = U\n",
    "        Rt = R\n",
    "        U += alpha *((1 - sigmond(X))* dU - lamda * Ut)\n",
    "        R += alpha *((1 - sigmond(X))* dR - lamda * Rt)\n",
    "        #back-propagation --second\n",
    "        dXH2 = np.dot(dHA1*dXH1, R.T)\n",
    "        for k in xrange(mask):\n",
    "            dU[k] = I2[k] * dHA2 * dXH2\n",
    "            dR[k] = H3[k] * dHA2 * dXH2\n",
    "        Ut = U\n",
    "        Rt = R\n",
    "        U += alpha *((1 - sigmond(X))* dU - lamda * Ut)\n",
    "        R += alpha *((1 - sigmond(X))* dR - lamda * Rt)\n",
    "        \n",
    "        #    I2   I1 Inow Inext\n",
    "        #    J2   J1 Jnow Jnext\n",
    "        #  dHA2 dHA1 \n",
    "        #  dXH2 dXH1\n",
    "        #H3  H2   H1 Hnow\n",
    "        \n",
    "        # the forth and other items\n",
    "        item = 3\n",
    "        Hnow = np.zeros((1, 10))\n",
    "        Hnow = Hnow[0]\n",
    "        while item < isum:\n",
    "            #feed-forward\n",
    "            i = training_set[user][item]-1\n",
    "            j = opt_set[user][item]-1\n",
    "            Inext = I[i]\n",
    "            Jnext = I[j]\n",
    "            Anow = np.dot(Inow, U) + np.dot(Jnow, R)\n",
    "            for k in xrange(mask):\n",
    "                Hnow[k] = sigmond(Anow[k])\n",
    "            X = np.dot(Hnow, Inext.T) - np.dot(Hnow, Jnext.T)\n",
    "            dXInext = Hnow \n",
    "            dXJnext = -Hnow\n",
    "            I[i] += alpha *((1 - sigmond(X))* dXInext - lamda * Inext)\n",
    "            I[j] += alpha *((1 - sigmond(X))* dXJnext - lamda * Jnext)\n",
    "            Inext = I[i]\n",
    "            Jnext = I[j]\n",
    "            #back-propagation --first\n",
    "            dXHnow = Inext - Jnext\n",
    "            dHAnow = np.zeros((1, 10))\n",
    "            for k in xrange(mask):\n",
    "                dHAnow[0][k] = Hnow[k] *(1 - Hnow[k])\n",
    "            dU = np.zeros((10, 10))\n",
    "            dR = np.zeros((10, 10))\n",
    "            for k in xrange(mask):\n",
    "                dU[k] = Inow[k] * dHAnow * dXHnow\n",
    "                dR[k] = H1[k] * dHAnow * dXHnow\n",
    "            Ut = U\n",
    "            Rt = R\n",
    "            U += alpha *((1 - sigmond(X))* dU - lamda * Ut)\n",
    "            R += alpha *((1 - sigmond(X))* dR - lamda * Rt)\n",
    "            \n",
    "            #back-propagation --second\n",
    "            dXH1 = np.dot(dHAnow*dXHnow, R.T)\n",
    "            for k in xrange(mask):\n",
    "                dU[k] = I1[k] * dHA1 * dXH1 ###TOHAVEWRONG!!!!!\n",
    "                dR[k] = H2[k] * dHA1 * dXH1\n",
    "            Ut = U\n",
    "            Rt = R\n",
    "            U += alpha *((1 - sigmond(X))* dU - lamda * Ut)\n",
    "            R += alpha *((1 - sigmond(X))* dR - lamda * Rt)\n",
    "            \n",
    "            #back-propagation --third\n",
    "            dXH2 = np.dot(dHA1*dXH1, R.T)\n",
    "            for k in xrange(mask):\n",
    "                dU[k] = I2[k] * dHA2 * dXH2\n",
    "                dR[k] = H3[k] * dHA2 * dXH2\n",
    "            Ut = U\n",
    "            Rt = R\n",
    "            U += alpha *((1 - sigmond(X))* dU - lamda * Ut)\n",
    "            R += alpha *((1 - sigmond(X))* dR - lamda * Rt)           \n",
    "            \n",
    "            #The next step\n",
    "            H3 = H2\n",
    "            H2 = H1\n",
    "            H1 = Hnow\n",
    "            #Hnow and Hnext will be calculate at first\n",
    "            I2 = I1 ; J2 = J1\n",
    "            I1 = Inow ; J1 = Jnow\n",
    "            Inow = Inext ; Jnow = Jnext \n",
    "            #I/Jnext will be found at first\n",
    "            dHA2 = dHA1\n",
    "            dHA1 = dHAnow\n",
    "            item += 1\n",
    "        H[user] = Hnow\n",
    "train()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict():\n",
    "    TP = 0\n",
    "    P = 0\n",
    "    user = 0\n",
    "    while user < unum:\n",
    "        H0 = np.zeros((1, 10))\n",
    "        H0[0] = H[user]\n",
    "        isum = len(data[user])\n",
    "        if isum > 1:\n",
    "            item = len(training_set[user])\n",
    "            while item < isum - 1:\n",
    "                temp = np.dot(H0, I.T)\n",
    "                sort_list = np.argsort(-temp[0])\n",
    "                for k in xrange(mask): #recall 10\n",
    "                    if (sort_list[k]+1) == data[user][item+1]:\n",
    "                        TP += 1\n",
    "                P += 1\n",
    "                It = I[data[user][item+1]-1]\n",
    "                At = np.dot(H0,R) + np.dot(It,U)\n",
    "                Ht = np.zeros((1, 10))\n",
    "                for k in xrange(mask):\n",
    "                    Ht[0][k] = sigmond(At[0][k])\n",
    "                H0 = Ht\n",
    "                item += 1\n",
    "        user += 1\n",
    "    return TP, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 Sat Oct  8 00:12:23 2016\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-f2df9956bc54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"iter\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mctime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mTP\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTP\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-796cbe6d6b7f>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[0mdU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mI1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdHA1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdXH1\u001b[0m \u001b[1;31m###TOHAVEWRONG!!!!!\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                 \u001b[0mdR\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mH2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdHA1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdXH1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m             \u001b[0mUt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mU\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mRt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tot_TP  = 0\n",
    "tot_P = 0\n",
    "alpha = 0.01\n",
    "for i in xrange(100):\n",
    "    print \"iter\", i, time.ctime()\n",
    "    train()\n",
    "    TP , P = predict()\n",
    "    result = float(TP) / P\n",
    "    print TP, P, result\n",
    "    tot_TP += TP\n",
    "    tot_P += P\n",
    "print tot_TP/tot_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iter 0 Fri Oct  7 15:19:19 2016\n",
    "7692 30117 0.255403924694\n",
    "iter 1 Fri Oct  7 15:20:20 2016\n",
    "7967 30117 0.264534980244\n",
    "iter 2 Fri Oct  7 15:21:20 2016\n",
    "7311 30117 0.242753262277\n",
    "iter 3 Fri Oct  7 15:22:49 2016\n",
    "7684 30117 0.255138293987\n",
    "iter 4 Fri Oct  7 15:23:58 2016\n",
    "7996 30117 0.265497891556\n",
    "iter 5 Fri Oct  7 15:24:55 2016\n",
    "8139 30117 0.270246040442\n",
    "iter 6 Fri Oct  7 15:25:57 2016\n",
    "7642 30117 0.253743732776\n",
    "iter 7 Fri Oct  7 15:26:55 2016\n",
    "7950 30117 0.263970514992\n",
    "iter 8 Fri Oct  7 15:27:52 2016\n",
    "7692 30117 0.255403924694\n",
    "iter 9 Fri Oct  7 15:28:49 2016\n",
    "7437 30117 0.246936945911\n",
    "iter 10 Fri Oct  7 15:29:46 2016\n",
    "7979 30117 0.264933426304\n",
    "iter 11 Fri Oct  7 15:30:43 2016\n",
    "7825 30117 0.259820035196\n",
    "iter 12 Fri Oct  7 15:31:40 2016\n",
    "7333 30117 0.243483746721\n",
    "iter 13 Fri Oct  7 15:32:36 2016\n",
    "8024 30117 0.26642759903\n",
    "iter 14 Fri Oct  7 15:33:32 2016\n",
    "7610 30117 0.252681209948\n",
    "iter 15 Fri Oct  7 15:34:28 2016\n",
    "7406 30117 0.245907626922\n",
    "iter 16 Fri Oct  7 15:35:24 2016\n",
    "7649 30117 0.253976159644\n",
    "iter 17 Fri Oct  7 15:36:21 2016\n",
    "7678 30117 0.254939070957\n",
    "iter 18 Fri Oct  7 15:37:16 2016\n",
    "8087 30117 0.268519440847\n",
    "iter 19 Fri Oct  7 15:38:13 2016\n",
    "7938 30117 0.263572068931\n",
    "iter 20 Fri Oct  7 15:39:09 2016\n",
    "7758 30117 0.257595378026\n",
    "iter 21 Fri Oct  7 15:40:05 2016\n",
    "7965 30117 0.264468572567\n",
    "iter 22 Fri Oct  7 15:41:01 2016\n",
    "7906 30117 0.262509546104\n",
    "iter 23 Fri Oct  7 15:41:57 2016\n",
    "7806 30117 0.259189162267\n",
    "iter 24 Fri Oct  7 15:42:54 2016\n",
    "7811 30117 0.259355181459\n",
    "iter 25 Fri Oct  7 15:43:51 2016\n",
    "7790 30117 0.258657900853\n",
    "iter 26 Fri Oct  7 15:44:48 2016\n",
    "7377 30117 0.244944715609\n",
    "iter 27 Fri Oct  7 15:45:44 2016\n",
    "7738 30117 0.256931301258\n",
    "iter 28 Fri Oct  7 15:46:41 2016\n",
    "7383 30117 0.245143938639\n",
    "iter 29 Fri Oct  7 15:47:38 2016\n",
    "7233 30117 0.240163362885\n",
    "iter 30 Fri Oct  7 15:48:41 2016\n",
    "7841 30117 0.26035129661\n",
    "iter 31 Fri Oct  7 15:49:38 2016\n",
    "7929 30117 0.263273234386\n",
    "iter 32 Fri Oct  7 15:50:35 2016\n",
    "7734 30117 0.256798485905\n",
    "iter 33 Fri Oct  7 15:51:32 2016\n",
    "7422 30117 0.246438888335\n",
    "iter 34 Fri Oct  7 15:52:29 2016\n",
    "8043 30117 0.267058471959\n",
    "iter 35 Fri Oct  7 15:53:25 2016\n",
    "7788 30117 0.258591493177\n",
    "iter 36 Fri Oct  7 15:54:22 2016\n",
    "7975 30117 0.264800610951\n",
    "iter 37 Fri Oct  7 15:55:17 2016\n",
    "7111 30117 0.236112494604\n",
    "iter 38 Fri Oct  7 15:56:13 2016\n",
    "7872 30117 0.261380615599\n",
    "iter 39 Fri Oct  7 15:57:10 2016\n",
    "8041 30117 0.266992064283\n",
    "iter 40 Fri Oct  7 15:58:06 2016\n",
    "8353 30117 0.277351661852\n",
    "iter 41 Fri Oct  7 15:59:02 2016\n",
    "7168 30117 0.238005113391\n",
    "iter 42 Fri Oct  7 15:59:59 2016\n",
    "7890 30117 0.26197828469\n",
    "iter 43 Fri Oct  7 16:00:55 2016\n",
    "7859 30117 0.2609489657\n",
    "iter 44 Fri Oct  7 16:01:50 2016\n",
    "7797 30117 0.258890327722\n",
    "iter 45 Fri Oct  7 16:02:47 2016\n",
    "7311 30117 0.242753262277\n",
    "iter 46 Fri Oct  7 16:03:43 2016\n",
    "8242 30117 0.273666035794\n",
    "iter 47 Fri Oct  7 16:04:39 2016\n",
    "7849 30117 0.260616927317\n",
    "iter 48 Fri Oct  7 16:05:35 2016\n",
    "8223 30117 0.273035162865\n",
    "iter 49 Fri Oct  7 16:06:31 2016\n",
    "8112 30117 0.269349536806\n",
    "iter 50 Fri Oct  7 16:07:27 2016\n",
    "7586 30117 0.251884317827\n",
    "iter 51 Fri Oct  7 16:08:23 2016\n",
    "7813 30117 0.259421589136\n",
    "iter 52 Fri Oct  7 16:09:20 2016\n",
    "7654 30117 0.254142178836\n",
    "iter 53 Fri Oct  7 16:10:15 2016\n",
    "7993 30117 0.265398280041\n",
    "iter 54 Fri Oct  7 16:11:12 2016\n",
    "7528 30117 0.249958495202\n",
    "iter 55 Fri Oct  7 16:12:09 2016\n",
    "7990 30117 0.265298668526\n",
    "iter 56 Fri Oct  7 16:13:06 2016\n",
    "8357 30117 0.277484477206\n",
    "iter 57 Fri Oct  7 16:14:03 2016\n",
    "7818 30117 0.259587608328\n",
    "iter 58 Fri Oct  7 16:15:00 2016\n",
    "7905 30117 0.262476342265\n",
    "iter 59 Fri Oct  7 16:15:57 2016\n",
    "8761 30117 0.290898827905\n",
    "iter 60 Fri Oct  7 16:16:53 2016\n",
    "8241 30117 0.273632831955\n",
    "iter 61 Fri Oct  7 16:17:51 2016\n",
    "8102 30117 0.269017498423\n",
    "iter 62 Fri Oct  7 16:18:49 2016\n",
    "8062 30117 0.267689344888\n",
    "iter 63 Fri Oct  7 16:19:47 2016\n",
    "7942 30117 0.263704884285\n",
    "iter 64 Fri Oct  7 16:20:44 2016\n",
    "7636 30117 0.253544509745\n",
    "iter 65 Fri Oct  7 16:21:41 2016\n",
    "7661 30117 0.254374605704\n",
    "iter 66 Fri Oct  7 16:22:37 2016\n",
    "7717 30117 0.256234020653\n",
    "iter 67 Fri Oct  7 16:23:34 2016\n",
    "8315 30117 0.276089915994\n",
    "iter 68 Fri Oct  7 16:24:31 2016\n",
    "7985 30117 0.265132649334\n",
    "iter 69 Fri Oct  7 16:25:27 2016\n",
    "7991 30117 0.265331872364\n",
    "iter 70 Fri Oct  7 16:26:24 2016\n",
    "7953 30117 0.264070126507\n",
    "iter 71 Fri Oct  7 16:27:20 2016\n",
    "7286 30117 0.241923166318\n",
    "iter 72 Fri Oct  7 16:28:16 2016\n",
    "7885 30117 0.261812265498\n",
    "iter 73 Fri Oct  7 16:29:18 2016\n",
    "7759 30117 0.257628581864\n",
    "iter 74 Fri Oct  7 16:30:27 2016\n",
    "7856 30117 0.260849354185\n",
    "iter 75 Sat Oct  8 00:11:29 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iter 0 Thu Oct  6 07:13:15 2016\n",
    "7576 30117 0.251552279444\n",
    "iter 1 Thu Oct  6 07:14:23 2016\n",
    "7095 30117 0.235581233191\n",
    "iter 2 Thu Oct  6 07:15:22 2016\n",
    "7090 30117 0.235415213999\n",
    "iter 3 Thu Oct  6 07:16:20 2016\n",
    "7560 30117 0.25102101803\n",
    "iter 4 Thu Oct  6 07:17:18 2016\n",
    "7414 30117 0.246173257629\n",
    "iter 5 Thu Oct  6 07:18:18 2016\n",
    "7429 30117 0.246671315204\n",
    "iter 6 Thu Oct  6 07:19:22 2016\n",
    "7665 30117 0.254507421058\n",
    "iter 7 Thu Oct  6 07:20:23 2016\n",
    "7710 30117 0.256001593784\n",
    "iter 8 Thu Oct  6 07:21:21 2016\n",
    "7217 30117 0.239632101471\n",
    "iter 9 Thu Oct  6 07:22:21 2016\n",
    "7248 30117 0.24066142046\n",
    "iter 10 Thu Oct  6 07:23:21 2016\n",
    "7169 30117 0.238038317229\n",
    "iter 11 Thu Oct  6 07:24:21 2016\n",
    "7409 30117 0.246007238437\n",
    "iter 12 Thu Oct  6 07:25:21 2016\n",
    "7252 30117 0.240794235814\n",
    "iter 13 Thu Oct  6 07:26:21 2016\n",
    "6825 30117 0.226616196832\n",
    "iter 14 Thu Oct  6 07:27:21 2016\n",
    "7120 30117 0.23641132915\n",
    "iter 15 Thu Oct  6 07:28:21 2016\n",
    "7266 30117 0.241259089551\n",
    "iter 16 Thu Oct  6 07:29:20 2016\n",
    "7480 30117 0.248364710961\n",
    "iter 17 Thu Oct  6 07:30:18 2016\n",
    "7236 30117 0.2402629744\n",
    "iter 18 Thu Oct  6 07:31:17 2016\n",
    "7420 30117 0.246372480659\n",
    "iter 19 Thu Oct  6 07:32:16 2016\n",
    "7625 30117 0.253179267523\n",
    "iter 20 Thu Oct  6 07:33:14 2016\n",
    "7486 30117 0.248563933991\n",
    "iter 21 Thu Oct  6 07:34:14 2016\n",
    "7537 30117 0.250257329747\n",
    "iter 22 Thu Oct  6 07:35:19 2016\n",
    "7388 30117 0.245309957831\n",
    "iter 23 Thu Oct  6 07:36:22 2016\n",
    "7767 30117 0.257894212571\n",
    "iter 24 Thu Oct  6 07:37:21 2016\n",
    "8011 30117 0.265995949132\n",
    "iter 25 Thu Oct  6 07:38:18 2016\n",
    "7055 30117 0.234253079656\n",
    "iter 26 Thu Oct  6 07:39:17 2016\n",
    "7182 30117 0.238469967128\n",
    "iter 27 Thu Oct  6 07:40:16 2016\n",
    "7358 30117 0.24431384268\n",
    "iter 28 Thu Oct  6 07:41:14 2016\n",
    "7400 30117 0.245708403891\n",
    "iter 29 Thu Oct  6 07:42:13 2016\n",
    "7411 30117 0.246073646113\n",
    "iter 30 Thu Oct  6 07:43:12 2016\n",
    "7389 30117 0.245343161669\n",
    "iter 31 Thu Oct  6 07:44:12 2016\n",
    "7337 30117 0.243616562075\n",
    "iter 32 Thu Oct  6 07:45:13 2016\n",
    "7449 30117 0.247335391971\n",
    "iter 33 Thu Oct  6 07:46:15 2016\n",
    "7292 30117 0.242122389348\n",
    "iter 34 Thu Oct  6 07:47:18 2016\n",
    "7138 30117 0.23700899824\n",
    "iter 35 Thu Oct  6 07:48:20 2016\n",
    "7477 30117 0.248265099445\n",
    "iter 36 Thu Oct  6 07:49:24 2016\n",
    "7540 30117 0.250356941262\n",
    "iter 37 Thu Oct  6 07:50:28 2016\n",
    "7732 30117 0.256732078228\n",
    "iter 38 Thu Oct  6 07:51:29 2016\n",
    "7278 30117 0.241657535611\n",
    "iter 39 Thu Oct  6 07:52:33 2016\n",
    "7702 30117 0.255735963077\n",
    "iter 40 Thu Oct  6 07:53:35 2016\n",
    "7596 30117 0.252216356211\n",
    "iter 41 Thu Oct  6 07:54:36 2016\n",
    "7561 30117 0.251054221868\n",
    "iter 42 Thu Oct  6 07:55:40 2016\n",
    "7392 30117 0.245442773185\n",
    "iter 43 Thu Oct  6 07:56:40 2016\n",
    "7509 30117 0.249327622273\n",
    "iter 44 Thu Oct  6 07:57:41 2016\n",
    "7590 30117 0.252017133181\n",
    "iter 45 Thu Oct  6 07:58:42 2016\n",
    "7387 30117 0.245276753993\n",
    "iter 46 Thu Oct  6 07:59:42 2016\n",
    "7562 30117 0.251087425706\n",
    "iter 47 Thu Oct  6 08:00:45 2016\n",
    "7594 30117 0.252149948534\n",
    "iter 48 Thu Oct  6 08:01:47 2016\n",
    "7255 30117 0.240893847329\n",
    "iter 49 Thu Oct  6 08:02:48 2016\n",
    "7709 30117 0.255968389946\n",
    "iter 50 Thu Oct  6 08:03:50 2016\n",
    "7384 30117 0.245177142478\n",
    "iter 51 Thu Oct  6 08:04:52 2016\n",
    "7357 30117 0.244280638842\n",
    "iter 52 Thu Oct  6 08:05:54 2016\n",
    "7468 30117 0.2479662649\n",
    "iter 53 Thu Oct  6 08:06:55 2016\n",
    "7556 30117 0.250888202676\n",
    "iter 54 Thu Oct  6 08:07:56 2016\n",
    "7465 30117 0.247866653385\n",
    "iter 55 Thu Oct  6 08:08:57 2016\n",
    "7915 30117 0.262808380649\n",
    "iter 56 Thu Oct  6 08:09:58 2016\n",
    "7769 30117 0.257960620248\n",
    "iter 57 Thu Oct  6 08:11:00 2016\n",
    "7872 30117 0.261380615599\n",
    "iter 58 Thu Oct  6 08:11:58 2016\n",
    "7937 30117 0.263538865093\n",
    "iter 59 Thu Oct  6 08:12:55 2016\n",
    "7396 30117 0.245575588538\n",
    "iter 60 Thu Oct  6 08:13:53 2016\n",
    "7642 30117 0.253743732776\n",
    "iter 61 Thu Oct  6 08:14:51 2016\n",
    "7731 30117 0.25669887439\n",
    "iter 62 Thu Oct  6 08:15:48 2016\n",
    "7188 30117 0.238669190158\n",
    "iter 63 Thu Oct  6 08:16:46 2016\n",
    "7742 30117 0.257064116612\n",
    "iter 64 Thu Oct  6 08:17:44 2016\n",
    "8054 30117 0.267423714181\n",
    "iter 65 Thu Oct  6 08:18:41 2016\n",
    "7885 30117 0.261812265498\n",
    "iter 66 Thu Oct  6 08:19:39 2016\n",
    "7915 30117 0.262808380649\n",
    "iter 67 Thu Oct  6 08:20:36 2016\n",
    "7993 30117 0.265398280041\n",
    "iter 68 Thu Oct  6 08:21:35 2016\n",
    "7921 30117 0.263007603679\n",
    "iter 69 Thu Oct  6 08:22:32 2016\n",
    "8001 30117 0.265663910748\n",
    "iter 70 Thu Oct  6 08:23:30 2016\n",
    "8076 30117 0.268154198625\n",
    "iter 71 Thu Oct  6 08:24:27 2016\n",
    "8000 30117 0.26563070691\n",
    "iter 72 Thu Oct  6 08:25:25 2016\n",
    "7452 30117 0.247435003486\n",
    "iter 73 Thu Oct  6 08:26:23 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iter 0 Thu Oct  6 00:06:37 2016\n",
    "6415 30117 0.213002623103\n",
    "iter 1 Thu Oct  6 00:10:21 2016\n",
    "6594 30117 0.21894611017\n",
    "iter 2 Thu Oct  6 00:14:11 2016\n",
    "6076 30117 0.201746521898\n",
    "iter 3 Thu Oct  6 00:17:56 2016\n",
    "6350 30117 0.21084437361\n",
    "iter 4 Thu Oct  6 00:21:45 2016\n",
    "6647 30117 0.220705913604\n",
    "iter 5 Thu Oct  6 00:25:29 2016\n",
    "6142 30117 0.20393797523\n",
    "iter 6 Thu Oct  6 00:29:08 2016\n",
    "6613 30117 0.219576983099\n",
    "iter 7 Thu Oct  6 00:32:14 2016\n",
    "6569 30117 0.218116014211\n",
    "iter 8 Thu Oct  6 00:34:46 2016\n",
    "6320 30117 0.209848258459\n",
    "iter 9 Thu Oct  6 00:37:23 2016\n",
    "6637 30117 0.22037387522\n",
    "iter 10 Thu Oct  6 00:40:01 2016\n",
    "6645 30117 0.220639505927\n",
    "iter 11 Thu Oct  6 00:42:36 2016\n",
    "6470 30117 0.214828834213\n",
    "iter 12 Thu Oct  6 00:45:14 2016\n",
    "6621 30117 0.219842613806\n",
    "iter 13 Thu Oct  6 00:47:45 2016\n",
    "6638 30117 0.220407079058\n",
    "iter 14 Thu Oct  6 00:50:14 2016\n",
    "6498 30117 0.215758541687\n",
    "iter 15 Thu Oct  6 00:52:44 2016\n",
    "6580 30117 0.218481256433\n",
    "iter 16 Thu Oct  6 00:55:12 2016\n",
    "6197 30117 0.20576418634\n",
    "iter 17 Thu Oct  6 00:57:41 2016\n",
    "6524 30117 0.216621841485\n",
    "iter 18 Thu Oct  6 01:00:13 2016\n",
    "6414 30117 0.212969419265\n",
    "iter 19 Thu Oct  6 01:02:46 2016\n",
    "6458 30117 0.214430388153\n",
    "iter 20 Thu Oct  6 01:05:18 2016\n",
    "6784 30117 0.225254839459\n",
    "iter 21 Thu Oct  6 01:07:53 2016\n",
    "6586 30117 0.218680479463\n",
    "iter 22 Thu Oct  6 01:10:29 2016\n",
    "6800 30117 0.225786100873\n",
    "iter 23 Thu Oct  6 01:13:04 2016\n",
    "6413 30117 0.212936215427\n",
    "iter 24 Thu Oct  6 01:15:37 2016\n",
    "6565 30117 0.217983198858\n",
    "iter 25 Thu Oct  6 01:18:12 2016\n",
    "6589 30117 0.218780090979\n",
    "iter 26 Thu Oct  6 01:20:41 2016\n",
    "6611 30117 0.219510575423\n",
    "iter 27 Thu Oct  6 01:23:15 2016\n",
    "6845 30117 0.2272802736\n",
    "iter 28 Thu Oct  6 01:25:51 2016\n",
    "6565 30117 0.217983198858\n",
    "iter 29 Thu Oct  6 01:28:07 2016\n",
    "6951 30117 0.230799880466\n",
    "iter 30 Thu Oct  6 01:30:09 2016\n",
    "7090 30117 0.235415213999\n",
    "iter 31 Thu Oct  6 01:32:11 2016\n",
    "6824 30117 0.226582992994\n",
    "iter 32 Thu Oct  6 01:34:11 2016\n",
    "6609 30117 0.219444167746\n",
    "iter 33 Thu Oct  6 01:36:11 2016\n",
    "6816 30117 0.226317362287\n",
    "iter 34 Thu Oct  6 01:38:12 2016\n",
    "6677 30117 0.221702028755\n",
    "iter 35 Thu Oct  6 01:40:13 2016\n",
    "6968 30117 0.231364345718\n",
    "iter 36 Thu Oct  6 01:42:14 2016\n",
    "6855 30117 0.227612311983\n",
    "iter 37 Thu Oct  6 01:44:14 2016\n",
    "6724 30117 0.223262609158\n",
    "iter 38 Thu Oct  6 01:46:15 2016\n",
    "7382 30117 0.245110734801\n",
    "iter 39 Thu Oct  6 01:48:16 2016\n",
    "6851 30117 0.22747949663\n",
    "iter 40 Thu Oct  6 01:50:17 2016\n",
    "6965 30117 0.231264734203\n",
    "iter 41 Thu Oct  6 01:52:18 2016\n",
    "6920 30117 0.229770561477\n",
    "iter 42 Thu Oct  6 01:54:19 2016\n",
    "6981 30117 0.231795995617\n",
    "iter 43 Thu Oct  6 01:56:19 2016\n",
    "6901 30117 0.229139688548\n",
    "iter 44 Thu Oct  6 01:58:20 2016\n",
    "6630 30117 0.220141448351\n",
    "iter 45 Thu Oct  6 02:00:19 2016\n",
    "7177 30117 0.238303947936\n",
    "iter 46 Thu Oct  6 02:01:19 2016\n",
    "7050 30117 0.234087060464\n",
    "iter 47 Thu Oct  6 02:02:17 2016\n",
    "7131 30117 0.236776571372\n",
    "iter 48 Thu Oct  6 02:03:16 2016\n",
    "6867 30117 0.228010758044\n",
    "iter 49 Thu Oct  6 02:04:14 2016\n",
    "7178 30117 0.238337151775\n",
    "iter 50 Thu Oct  6 02:05:13 2016\n",
    "6726 30117 0.223329016834\n",
    "iter 51 Thu Oct  6 02:06:12 2016\n",
    "6989 30117 0.232061626324\n",
    "iter 52 Thu Oct  6 02:07:10 2016\n",
    "6951 30117 0.230799880466\n",
    "iter 53 Thu Oct  6 02:08:09 2016\n",
    "7085 30117 0.235249194807\n",
    "iter 54 Thu Oct  6 02:09:08 2016\n",
    "7056 30117 0.234286283494\n",
    "iter 55 Thu Oct  6 02:10:07 2016\n",
    "7134 30117 0.236876182887\n",
    "iter 56 Thu Oct  6 02:11:06 2016\n",
    "6876 30117 0.228309592589\n",
    "iter 57 Thu Oct  6 02:12:05 2016\n",
    "6865 30117 0.227944350367\n",
    "iter 58 Thu Oct  6 02:13:04 2016\n",
    "7120 30117 0.23641132915\n",
    "iter 59 Thu Oct  6 02:14:03 2016\n",
    "6491 30117 0.215526114819\n",
    "iter 60 Thu Oct  6 02:15:03 2016\n",
    "6837 30117 0.227014642893\n",
    "iter 61 Thu Oct  6 02:16:04 2016\n",
    "7142 30117 0.237141813594\n",
    "iter 62 Thu Oct  6 02:17:05 2016\n",
    "6801 30117 0.225819304712\n",
    "iter 63 Thu Oct  6 02:18:04 2016\n",
    "6708 30117 0.222731347744\n",
    "iter 64 Thu Oct  6 02:19:03 2016\n",
    "7085 30117 0.235249194807\n",
    "iter 65 Thu Oct  6 02:20:02 2016\n",
    "6869 30117 0.22807716572\n",
    "iter 66 Thu Oct  6 02:21:01 2016\n",
    "6906 30117 0.22930570774\n",
    "iter 67 Thu Oct  6 02:22:00 2016\n",
    "7039 30117 0.233721818242\n",
    "iter 68 Thu Oct  6 02:22:58 2016\n",
    "7110 30117 0.236079290766\n",
    "iter 69 Thu Oct  6 02:23:57 2016\n",
    "6964 30117 0.231231530365\n",
    "iter 70 Thu Oct  6 02:24:57 2016\n",
    "6849 30117 0.227413088953\n",
    "iter 71 Thu Oct  6 02:25:57 2016\n",
    "7184 30117 0.238536374805\n",
    "iter 72 Thu Oct  6 02:26:57 2016\n",
    "7090 30117 0.235415213999\n",
    "iter 73 Thu Oct  6 02:27:56 2016\n",
    "7050 30117 0.234087060464\n",
    "iter 74 Thu Oct  6 02:28:57 2016\n",
    "6972 30117 0.231497161072\n",
    "iter 75 Thu Oct  6 02:29:57 2016\n",
    "7018 30117 0.233024537637\n",
    "iter 76 Thu Oct  6 02:30:57 2016\n",
    "7025 30117 0.233256964505\n",
    "iter 77 Thu Oct  6 02:31:57 2016\n",
    "7142 30117 0.237141813594\n",
    "iter 78 Thu Oct  6 02:32:57 2016\n",
    "7300 30117 0.242388020055\n",
    "iter 79 Thu Oct  6 02:33:57 2016\n",
    "7019 30117 0.233057741475\n",
    "iter 80 Thu Oct  6 02:34:57 2016\n",
    "7007 30117 0.232659295415\n",
    "iter 81 Thu Oct  6 02:35:57 2016\n",
    "7165 30117 0.237905501876\n",
    "iter 82 Thu Oct  6 02:36:57 2016\n",
    "7013 30117 0.232858518445\n",
    "iter 83 Thu Oct  6 02:37:57 2016\n",
    "6827 30117 0.226682604509\n",
    "iter 84 Thu Oct  6 02:38:57 2016\n",
    "7494 30117 0.248829564698\n",
    "iter 85 Thu Oct  6 02:39:58 2016\n",
    "7409 30117 0.246007238437\n",
    "iter 86 Thu Oct  6 02:40:58 2016\n",
    "7181 30117 0.23843676329\n",
    "iter 87 Thu Oct  6 02:41:57 2016\n",
    "7636 30117 0.253544509745\n",
    "iter 88 Thu Oct  6 02:42:56 2016\n",
    "7168 30117 0.238005113391\n",
    "iter 89 Thu Oct  6 02:43:55 2016\n",
    "7543 30117 0.250456552778\n",
    "iter 90 Thu Oct  6 02:44:54 2016\n",
    "7604 30117 0.252481986918\n",
    "iter 91 Thu Oct  6 02:45:53 2016\n",
    "7281 30117 0.241757147126\n",
    "iter 92 Thu Oct  6 02:46:53 2016\n",
    "7312 30117 0.242786466115\n",
    "iter 93 Thu Oct  6 02:47:52 2016\n",
    "7178 30117 0.238337151775\n",
    "iter 94 Thu Oct  6 02:48:52 2016\n",
    "7099 30117 0.235714048544\n",
    "iter 95 Thu Oct  6 02:49:52 2016\n",
    "7227 30117 0.239964139855\n",
    "iter 96 Thu Oct  6 02:50:51 2016\n",
    "7261 30117 0.241093070359\n",
    "iter 97 Thu Oct  6 02:51:51 2016\n",
    "7604 30117 0.252481986918\n",
    "iter 98 Thu Oct  6 02:52:51 2016\n",
    "7604 30117 0.252481986918\n",
    "iter 99 Thu Oct  6 02:53:50 2016\n",
    "7289 30117 0.242022777833\n",
    "0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modefied\n",
    "The new copy reset the opt_set in every training set\n",
    "and use a new learning data : 0.05\n",
    "The iter 0 in fact is iter 7\n",
    "\n",
    "iter 15 Thu Oct  6 00:01:53 2016\n",
    "4199 30117 0.139422917289\n",
    "changed alpha = 0.01\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
